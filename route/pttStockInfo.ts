import express, { Router, NextFunction, Request, Response } from 'express';
import service, { isRePosts, processSinglePostToMessage, parsePosts } from '../service/pttStockInfo';
import lineService from '../service/lineService';
import { delay } from '../utility/delay';
import { ILineToken, TokenLevel } from '../model/lineToken';
import { AuthorModel, IAuthor } from '../model/Author';
import * as AuthorService from '../service/pttStockAuthor';
import { IPostInfo, PostInfoModel } from '../model/PostInfo';
import { todayDate, today } from '../utility/dateTime';
import config from '../utility/config';
import { AuthorHistoricalCache, IHistoricalCache } from '../model/AuthorHistoricalCache';
import { getStockNoFromTitle } from '../service/pttStockAuthor';
import { authentication } from '../utility/auth';

const router: Router = express.Router();

router.get('/list', async (req: Request, res: Response, next: NextFunction) => {
  var savedPosts = await service.getLast50Posts();
  res.json({ posts: savedPosts });
});

router.get('/new', async (req: Request, res: Response, next: NextFunction) => {
  const newPosts = await service.getNewPosts();

  if (newPosts && newPosts.length) {
    try {
      const tokenInfos: ILineToken[] | null = await retrieveTokenInfo(
        req.query.channel as string,
        req.query.channels as string
      );
      //å…ˆçµ±ä¸€æ‹¿æ‰€æœ‰çš„author, ä¹‹å¾Œæœƒæ”¹æˆby user è¨‚é–±æ–¹å¼
      const subscribeAuthor: IAuthor[] = await AuthorModel.find({}).lean();
      if (tokenInfos != null && tokenInfos.length > 0) {
        for (const tokenInfo of tokenInfos) {
          for (const post of newPosts) {
            const authorInfo = subscribeAuthor.find((x) => x.name === post.author);
            const isSubscribed = authorInfo != null;
            if (post.tag === 'æ¨™çš„' && !isRePosts(post)) {
              let notifyContent: string[] = [];
              if (tokenInfo.tokenLevel.includes(TokenLevel.Test)) {
                notifyContent = ['', ''];
                if (isSubscribed && post.tag == 'æ¨™çš„') {
                  notifyContent.push(`ã€âœ¨âœ¨å¤§ç¥žä¾†å›‰âœ¨âœ¨ã€‘`);
                }
                notifyContent.push(`[${post.tag}] ${post.title}`);
                notifyContent.push(`ä½œè€…: ${post.author} ${authorInfo ? `ðŸ‘:${authorInfo.likes}` : ''}`);
                notifyContent.push('');
                notifyContent.push(`${config.CLIENT_URL}/ptt/author/${post.author}?token=${tokenInfo.channel}`);
              } else {
                notifyContent = processSinglePostToMessage(post, isSubscribed);
                if (post.tag == 'æ¨™çš„' && getStockNoFromTitle(post)) {
                  notifyContent.push(`${config.CLIENT_URL}/ptt/author/${post.author}`);
                }
              }
              await lineService.sendMessage(tokenInfo.token, notifyContent.join('\n'));
              await delay(25);
            }
          }
        }
      }
    } catch (error) {
      console.log('send notify fail', error);
    }
  }

  res.json({ message: `send notify success` });
});

interface ResultItem extends AuthorService.PriceInfoResponse {
  post: IPostInfo;
  isRecentPost: boolean;
}

router.get('/author/list', async (req: Request, res: Response, next: NextFunction) => {
  const result = await AuthorModel.find().sort({ likes: -1 }).lean().exec();

  // try {
  //   // æ ¹æ®ä½œè€…åæŸ¥æ‰¾ä½œè€…åŠå…¶å¸–å­
  //   const authorNames = ['uzgo', 'kobekid']; // å‡è®¾è¿™é‡Œæ˜¯ä½ çš„ä½œè€…åæ•°ç»„
  //   const authorsWithPosts = await AuthorModel.aggregate([
  //     { $match: { name: { $in: authorNames } } },
  //     {
  //       $lookup: {
  //         from: 'postinfos', // å‡è®¾è¿™æ˜¯å¸–å­é›†åˆçš„åç§°
  //         localField: 'name', // ä½¿ç”¨ä½œè€…çš„åå­—è¿›è¡ŒåŒ¹é…
  //         foreignField: 'author', // å‡è®¾è¿™æ˜¯å¸–å­ä¸­ä½œè€…çš„å­—æ®µå
  //         as: 'posts',
  //       },
  //     },
  //     { $project: { name: 1, posts: { $slice: ['$posts', 5] } } }, // é™åˆ¶æ¯ä¸ªä½œè€…çš„å¸–å­æ•°é‡ä¸º 5 æ¡
  //   ]);

  //   console.log(JSON.stringify(authorsWithPosts));
  // } catch (err) {
  //   console.error(err);
  // }

  res.json(result);
});

router.get('/author/:id', async (req: Request, res: Response, next: NextFunction) => {
  const authorId = req.params.id;
  const refresh = Boolean(req.query.refresh === 'true');
  const existingResult = await AuthorHistoricalCache.findOne({ authorId }).lean().exec();
  // Check if there is an existing result and if it's not expired
  if (!refresh && existingResult && Date.now() - existingResult.timestamp < 3 * 60 * 60 * 1000) {
    res.json(existingResult.data);
  } else {
    const result: ResultItem[] = [];
    const $ = await AuthorService.getHtmlSource(authorId);
    const posts = parsePosts($, +new Date());

    const storedPosts = await PostInfoModel.find({ author: authorId })
      .sort({ id: -1 }) // æŒ‰ id é™åºæŽ’åˆ—
      .limit(8) // åªè¿”å›žæœ€è¿‘çš„äº”ç¯‡
      .lean()
      .exec();

    const combinedPosts = [...posts, ...storedPosts].filter(
      (postInfo, index, self) => index === self.findIndex((item) => item.id === postInfo.id)
    );
    combinedPosts.sort((a, b) => b.id - a.id);
    //const targetPosts: IPostInfo[] = AuthorService.getTargetPosts(posts);
    console.log(`posts.length:${combinedPosts.length}`);
    for (let i = 0; i < Math.min(combinedPosts.length, 8); i++) {
      const info = combinedPosts[i];
      const stockNo = AuthorService.getStockNoFromTitle(info);

      const postDate = new Date(info.id * 1000);
      const isRecentPost = AuthorService.isPostedInOneWeek(postDate, todayDate());
      var target: ResultItem = {
        stockNo,
        historicalInfo: [],
        processedData: [],
        post: info,
        isRecentPost,
      };
      if (stockNo) {
        const targetDates = AuthorService.getDateRangeBaseOnPostedDate(postDate, todayDate());
        const resultInfo: AuthorService.PriceInfoResponse | null = await AuthorService.getPriceInfoByDates(
          stockNo,
          targetDates[0],
          targetDates[1]
        );
        if (resultInfo) {
          isRecentPost && AuthorService.processRecentPost(postDate, resultInfo);
          target.historicalInfo = resultInfo.historicalInfo;
          target.processedData = resultInfo.processedData;
        }
      }

      result.push(target);
    }
    // Delete any existing result for the authorId
    await AuthorHistoricalCache.deleteMany({ authorId }).exec();
    const newResult: IHistoricalCache = {
      timestamp: +Date.now(),
      authorId,
      data: result,
    };
    await new AuthorHistoricalCache(newResult).save();

    res.json(result);
  }
});

router.get('/author/:id/like', authentication, async (req: Request, res: Response, next: NextFunction) => {
  const authorId = req.params.id;
  try {
    let authorInfo = await AuthorModel.findOne({ name: authorId }).exec();

    if (!authorInfo) {
      authorInfo = new AuthorModel({
        name: authorId,
        likes: 0,
        dislikes: 0,
      });
    }

    authorInfo.likes += 1;

    await authorInfo.save();

    res.json('Liked!');
  } catch (error) {
    console.error('Error while liking author:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

export default router;

async function retrieveTokenInfo(channel: string, channels: string) {
  let tokenInfos: ILineToken[] | null = [];

  if (channel) {
    const token = await lineService.getTokenByChannel(channel);
    if (token == null) {
      throw new Error('No match token for ' + channel);
    }
    tokenInfos.push(token);
  } else if (channels) {
    const splittedChannel = channels.split(',');
    const savedTokens = await lineService.getTokensByChannels(splittedChannel);
    if (savedTokens == null || savedTokens.length < 1) {
      throw new Error('No match tokens for ' + channels);
    }
    tokenInfos = savedTokens;
  } else {
    const retrivedTokens = await lineService.getAllEnabledChannel();
    if (retrivedTokens == null || retrivedTokens.length < 1) {
      throw new Error('No match tokens for ' + channels);
    }
    tokenInfos = retrivedTokens;
  }
  return tokenInfos;
}
